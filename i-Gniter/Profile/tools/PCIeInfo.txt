&&&& RUNNING TensorRT.trtexec [TensorRT v8001] # trtexec --loadEngine=vgg19_1_1_64.engine --avgRuns=50 --duration=10 --shapes=actual_input_1:1x3x224x224
[10/22/2022-02:16:17] [I] === Model Options ===
[10/22/2022-02:16:17] [I] Format: *
[10/22/2022-02:16:17] [I] Model:
[10/22/2022-02:16:17] [I] Output:
[10/22/2022-02:16:17] [I] === Build Options ===
[10/22/2022-02:16:17] [I] Max batch: explicit
[10/22/2022-02:16:17] [I] Workspace: 16 MiB
[10/22/2022-02:16:17] [I] minTiming: 1
[10/22/2022-02:16:17] [I] avgTiming: 8
[10/22/2022-02:16:17] [I] Precision: FP32
[10/22/2022-02:16:17] [I] Calibration:
[10/22/2022-02:16:17] [I] Refit: Disabled
[10/22/2022-02:16:17] [I] Sparsity: Disabled
[10/22/2022-02:16:17] [I] Safe mode: Disabled
[10/22/2022-02:16:17] [I] Restricted mode: Disabled
[10/22/2022-02:16:17] [I] Save engine:
[10/22/2022-02:16:17] [I] Load engine: vgg19_1_1_64.engine
[10/22/2022-02:16:17] [I] NVTX verbosity: 0
[10/22/2022-02:16:17] [I] Tactic sources: Using default tactic sources
[10/22/2022-02:16:17] [I] timingCacheMode: local
[10/22/2022-02:16:17] [I] timingCacheFile:
[10/22/2022-02:16:17] [I] Input(s)s format: fp32:CHW
[10/22/2022-02:16:17] [I] Output(s)s format: fp32:CHW
[10/22/2022-02:16:17] [I] Input build shape: actual_input_1=1x3x224x224+1x3x224x224+1x3x224x224
[10/22/2022-02:16:17] [I] Input calibration shapes: model
[10/22/2022-02:16:17] [I] === System Options ===
[10/22/2022-02:16:17] [I] Device: 0
[10/22/2022-02:16:17] [I] DLACore:
[10/22/2022-02:16:17] [I] Plugins:
[10/22/2022-02:16:17] [I] === Inference Options ===
[10/22/2022-02:16:17] [I] Batch: Explicit
[10/22/2022-02:16:17] [I] Input inference shape: actual_input_1=1x3x224x224
[10/22/2022-02:16:17] [I] Iterations: 10
[10/22/2022-02:16:17] [I] Duration: 10s (+ 200ms warm up)
[10/22/2022-02:16:17] [I] Sleep time: 0ms
[10/22/2022-02:16:17] [I] Streams: 1
[10/22/2022-02:16:17] [I] ExposeDMA: Disabled
[10/22/2022-02:16:17] [I] Data transfers: Enabled
[10/22/2022-02:16:17] [I] Spin-wait: Disabled
[10/22/2022-02:16:17] [I] Multithreading: Disabled
[10/22/2022-02:16:17] [I] CUDA Graph: Disabled
[10/22/2022-02:16:17] [I] Separate profiling: Disabled
[10/22/2022-02:16:17] [I] Time Deserialize: Disabled
[10/22/2022-02:16:17] [I] Time Refit: Disabled
[10/22/2022-02:16:17] [I] Skip inference: Disabled
[10/22/2022-02:16:17] [I] Inputs:
[10/22/2022-02:16:17] [I] === Reporting Options ===
[10/22/2022-02:16:17] [I] Verbose: Disabled
[10/22/2022-02:16:17] [I] Averages: 50 inferences
[10/22/2022-02:16:17] [I] Percentile: 99
[10/22/2022-02:16:17] [I] Dump refittable layers:Disabled
[10/22/2022-02:16:17] [I] Dump output: Disabled
[10/22/2022-02:16:17] [I] Profile: Disabled
[10/22/2022-02:16:17] [I] Export timing to JSON file:
[10/22/2022-02:16:17] [I] Export output to JSON file:
[10/22/2022-02:16:17] [I] Export profile to JSON file:
[10/22/2022-02:16:17] [I]
[10/22/2022-02:16:17] [I] === Device Information ===
[10/22/2022-02:16:17] [I] Selected Device: NVIDIA Tesla T4
[10/22/2022-02:16:17] [I] Compute Capability: 7.5
[10/22/2022-02:16:17] [I] SMs: 40
[10/22/2022-02:16:17] [I] Compute Clock Rate: 1.59 GHz
[10/22/2022-02:16:17] [I] Device Global Memory: 15109 MiB
[10/22/2022-02:16:17] [I] Shared Memory per SM: 64 KiB
[10/22/2022-02:16:17] [I] Memory Bus Width: 256 bits (ECC enabled)
[10/22/2022-02:16:17] [I] Memory Clock Rate: 5.001 GHz
[10/22/2022-02:16:17] [I]
[10/22/2022-02:16:17] [I] TensorRT version: 8001
[10/22/2022-02:16:18] [I] [TRT] [MemUsageChange] Init CUDA: CPU +330, GPU +0, now: CPU 1021, GPU 273 (MiB)
[10/22/2022-02:16:18] [I] [TRT] Loaded engine size: 684 MB
[10/22/2022-02:16:18] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine begin: CPU 1021 MiB, GPU 273 MiB
[10/22/2022-02:16:20] [10/22/2022-02:16:20] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +397, GPU +166, now: CPU 1419, GPU 1125 (MiB)
[10/22/2022-02:16:21] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +159, GPU +172, now: CPU 1578, GPU 1297 (MiB)
[10/22/2022-02:16:21] [10/22/2022-02:16:21] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1578, GPU 1279 (MiB)
[10/22/2022-02:16:21] [I] [TRT] [MemUsageSnapshot] deserializeCudaEngine end: CPU 1578 MiB, GPU 1279 MiB
[10/22/2022-02:16:21] [I] Engine loaded in 4.14378 sec.
[10/22/2022-02:16:21] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation begin: CPU 893 MiB, GPU 1279 MiB
[10/22/2022-02:16:21] [10/22/2022-02:16:21] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +10, now: CPU 893, GPU 1289 (MiB)
[10/22/2022-02:16:21] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 893, GPU 1297 (MiB)
[10/22/2022-02:16:21] [10/22/2022-02:16:21] [I] [TRT] [MemUsageSnapshot] ExecutionContext creation end: CPU 893 MiB, GPU 2395 MiB
[10/22/2022-02:16:21] [I] Created input binding for actual_input_1 with dimensions 1x3x224x224
[10/22/2022-02:16:21] [I] Created output binding for output1 with dimensions 1x1000
[10/22/2022-02:16:21] [I] Starting inference
[10/22/2022-02:16:31] [I] Warmup completed 18 queries over 200 ms
[10/22/2022-02:16:31] [I] Timing trace has 1071 queries over 10.0231 s
[10/22/2022-02:16:31] [I]
[10/22/2022-02:16:31] [I] === Trace details ===
[10/22/2022-02:16:31] [I] Trace averages of 50 runs:
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.21144 ms - Host latency: 9.31832 ms (end to end 18.3814 ms, enqueue 0.124792 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.35084 ms - Host latency: 9.45772 ms (end to end 18.6112 ms, enqueue 0.11855 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.31077 ms - Host latency: 9.41759 ms (end to end 18.5588 ms, enqueue 0.115955 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.30461 ms - Host latency: 9.4143 ms (end to end 18.5253 ms, enqueue 0.131355 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.38032 ms - Host latency: 9.48732 ms (end to end 18.6893 ms, enqueue 0.134185 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.31256 ms - Host latency: 9.42054 ms (end to end 18.5462 ms, enqueue 0.130649 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.40994 ms - Host latency: 9.51681 ms (end to end 18.7423 ms, enqueue 0.124409 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.30146 ms - Host latency: 9.40843 ms (end to end 18.5148 ms, enqueue 0.128945 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.37841 ms - Host latency: 9.485 ms (end to end 18.6853 ms, enqueue 0.115859 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.28205 ms - Host latency: 9.38892 ms (end to end 18.4875 ms, enqueue 0.115986 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.39937 ms - Host latency: 9.50638 ms (end to end 18.7265 ms, enqueue 0.114346 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.32144 ms - Host latency: 9.43009 ms (end to end 18.5713 ms, enqueue 0.118828 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.38283 ms - Host latency: 9.48923 ms (end to end 18.6966 ms, enqueue 0.11751 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.34038 ms - Host latency: 9.44669 ms (end to end 18.61 ms, enqueue 0.115918 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.36552 ms - Host latency: 9.47205 ms (end to end 18.6507 ms, enqueue 0.117666 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.34941 ms - Host latency: 9.45586 ms (end to end 18.628 ms, enqueue 0.118086 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.40514 ms - Host latency: 9.51215 ms (end to end 18.7291 ms, enqueue 0.119443 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.33634 ms - Host latency: 9.4426 ms (end to end 18.6002 ms, enqueue 0.116133 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.37477 ms - Host latency: 9.48111 ms (end to end 18.668 ms, enqueue 0.118574 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.3466 ms - Host latency: 9.45297 ms (end to end 18.6198 ms, enqueue 0.11627 ms)
[10/22/2022-02:16:31] [I] Average on 50 runs - GPU latency: 9.38541 ms - Host latency: 9.49205 ms (end to end 18.6928 ms, enqueue 0.115117 ms)
[10/22/2022-02:16:31] [I]
[10/22/2022-02:16:31] [I] === Performance summary ===
[10/22/2022-02:16:31] [I] Throughput: 106.854 qps
[10/22/2022-02:16:31] [I] Latency: min = 9.12524 ms, max = 10.0771 ms, mean = 9.4529 ms, median = 9.42383 ms, percentile(99%) = 9.84424 ms
[10/22/2022-02:16:31] [I] End-to-End Host Latency: min = 17.9812 ms, max = 20.4304 ms, mean = 18.6174 ms, median = 18.5616 ms, percentile(99%) = 19.4558 ms
[10/22/2022-02:16:31] [I] Enqueue Time: min = 0.105225 ms, max = 0.256348 ms, mean = 0.120317 ms, median = 0.114258 ms, percentile(99%) = 0.171539 ms
[10/22/2022-02:16:31] [I] H2D Latency: min = 0.100586 ms, max = 0.195801 ms, mean = 0.102364 ms, median = 0.101562 ms, percentile(99%) = 0.108887 ms
[10/22/2022-02:16:31] [I] GPU Compute Time: min = 9.01947 ms, max = 9.96997 ms, mean = 9.34591 ms, median = 9.31836 ms, percentile(99%) = 9.73608 ms
[10/22/2022-02:16:31] [I] D2H Latency: min = 0.00390625 ms, max = 0.00683594 ms, mean = 0.00462685 ms, median = 0.00439453 ms, percentile(99%) = 0.00634766 ms
[10/22/2022-02:16:31] [I] Total Host Walltime: 10.0231 s
[10/22/2022-02:16:31] [I] Total GPU Compute Time: 10.0095 s
[10/22/2022-02:16:31] [I] Explanations of the performance metrics are printed in the verbose logs.
[10/22/2022-02:16:31] [I]
&&&& PASSED TensorRT.trtexec [TensorRT v8001] # trtexec --loadEngine=vgg19_1_1_64.engine --avgRuns=50 --duration=10 --shapes=actual_input_1:1x3x224x224
[10/22/2022-02:16:31] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 894, GPU 2163 (MiB)
